{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "S4-RedesNeuronalesConvolutivas.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mOWEqcSGkJ3p",
        "colab_type": "text"
      },
      "source": [
        "# Redes Neuronales Convolucionales"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fGfsPmYuj9no",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D # --> Parte Convolituva"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WVse9LEhsc4l",
        "colab_type": "text"
      },
      "source": [
        "Bajamos la base de **MNIST**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OPHtEQLUrvIz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TUjxq5ULs3Os",
        "colab_type": "text"
      },
      "source": [
        "Imrimimos la etiqueta de **Y** y los valores de **X**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q9H17vXIsAq1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "outputId": "5ba87f73-9977-4889-80ec-89bd6461bbe2"
      },
      "source": [
        "import pylab as plt\n",
        "print(X_train.shape)\n",
        "\n",
        "n = 1\n",
        "plt.imshow(X_train[n])\n",
        "print(y_train[n])"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n",
            "0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EH92J3wvtN7z",
        "colab_type": "text"
      },
      "source": [
        "### Prepocesamiento de los Datos\n",
        "\n",
        "1. Hacemos una trasformación generando una dimensión adicional para que funcione con imagenes a color"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EsPidQ4gsYGf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1)\n",
        "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1)\n",
        "input_shape = (28, 28, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FVYgDM1XtBR7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cd219be7-1747-4ed5-d8ad-fef63b6d8404"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4XeXlflCuyVA",
        "colab_type": "text"
      },
      "source": [
        "2. Sacamos una muestra de 3K datos, para reducir el tema de computo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BwNTUrZUuJp0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "85893523-b8e9-4a46-bbcd-861ed0b0f5d2"
      },
      "source": [
        "data_slice = 20000\n",
        "print(X_train.shape)\n",
        "X_train = X_train[:data_slice, :, :, :]\n",
        "y_train = y_train[:data_slice]\n",
        "X_test = X_test[:data_slice, :, :, :]\n",
        "y_test = y_test[:data_slice]\n",
        "print(X_train.shape)"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28, 1)\n",
            "(20000, 28, 28, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4wIoa1eSu88O",
        "colab_type": "text"
      },
      "source": [
        "3. Escalamos de 0 a 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqReyCDVuxaa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "# Escalamos\n",
        "X_train /= 255\n",
        "X_test /= 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TFIX762tvsnb",
        "colab_type": "text"
      },
      "source": [
        "4. Hacemos un One Hot Encoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4CMLYZi6voQ_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train = keras.utils.to_categorical(y_train, 10)\n",
        "y_test = keras.utils.to_categorical(y_test, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XEGc9ja3wo4B",
        "colab_type": "text"
      },
      "source": [
        "## Creamos el modelo de Redes Neuronales Convolutivas\n",
        "\n",
        "0. Incializamos el modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZ6OT1_PwpLu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "modelo = Sequential()\n",
        "# Parte Convolutiva\n",
        "modelo.add(Conv2D(256, kernel_size=(7,7), activation='relu', input_shape=input_shape))\n",
        "modelo.add(Conv2D(128, kernel_size=(6,6), activation='relu'))\n",
        "modelo.add(Conv2D(64, kernel_size=(5,5), activation='relu'))\n",
        "modelo.add(Conv2D(32, kernel_size=(4,4), activation='relu'))\n",
        "modelo.add(Conv2D(16, kernel_size=(3,3), activation='relu'))\n",
        "modelo.add(MaxPooling2D(pool_size=(2,2)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jo0tSo_pxx1c",
        "colab_type": "text"
      },
      "source": [
        "1. Hacemos el modelo unidimensional"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Uv9MozYxxBl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Lo hacemos un modelo unidimensional\n",
        "modelo.add(Flatten())\n",
        "modelo.add(Dense(128, activation='relu')) # unidades, activacion\n",
        "modelo.add(Dense(64, activation='relu')) # unidades, activacion\n",
        "modelo.add(Dense(32, activation='relu')) # unidades, activacion\n",
        "modelo.add(Dense(10, activation='softmax')) # En la capa de salida damos 10 salidas usando softmax"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0B9OHIOSyeri",
        "colab_type": "text"
      },
      "source": [
        "2. Compilamos el modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EuNzweAcyX8I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "modelo.compile(loss = keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adadelta(), metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OorcI8tAzCYY",
        "colab_type": "text"
      },
      "source": [
        "3. Ajustamos el modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cSMBu77ry21F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7387ac65-faab-4198-9c8c-729e26727df2"
      },
      "source": [
        "modelo.fit(X_train, y_train, batch_size=250, epochs=100, #verbose=0, \n",
        "           validation_data=(X_test, y_test))"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 20000 samples, validate on 10000 samples\n",
            "Epoch 1/100\n",
            "20000/20000 [==============================] - 4s 198us/step - loss: 1.5562 - accuracy: 0.4854 - val_loss: 0.4431 - val_accuracy: 0.8723\n",
            "Epoch 2/100\n",
            "20000/20000 [==============================] - 3s 162us/step - loss: 0.3782 - accuracy: 0.8885 - val_loss: 0.1963 - val_accuracy: 0.9390\n",
            "Epoch 3/100\n",
            "20000/20000 [==============================] - 3s 162us/step - loss: 0.1657 - accuracy: 0.9512 - val_loss: 0.1036 - val_accuracy: 0.9682\n",
            "Epoch 4/100\n",
            "20000/20000 [==============================] - 3s 162us/step - loss: 0.1219 - accuracy: 0.9631 - val_loss: 0.1021 - val_accuracy: 0.9672\n",
            "Epoch 5/100\n",
            "20000/20000 [==============================] - 3s 162us/step - loss: 0.0916 - accuracy: 0.9727 - val_loss: 0.0778 - val_accuracy: 0.9758\n",
            "Epoch 6/100\n",
            "20000/20000 [==============================] - 3s 163us/step - loss: 0.0812 - accuracy: 0.9769 - val_loss: 0.0680 - val_accuracy: 0.9787\n",
            "Epoch 7/100\n",
            "20000/20000 [==============================] - 3s 163us/step - loss: 0.0606 - accuracy: 0.9814 - val_loss: 0.0590 - val_accuracy: 0.9805\n",
            "Epoch 8/100\n",
            "20000/20000 [==============================] - 3s 162us/step - loss: 0.0563 - accuracy: 0.9837 - val_loss: 0.0916 - val_accuracy: 0.9700\n",
            "Epoch 9/100\n",
            "20000/20000 [==============================] - 3s 163us/step - loss: 0.0458 - accuracy: 0.9865 - val_loss: 0.0604 - val_accuracy: 0.9827\n",
            "Epoch 10/100\n",
            "20000/20000 [==============================] - 3s 163us/step - loss: 0.0414 - accuracy: 0.9865 - val_loss: 0.0653 - val_accuracy: 0.9790\n",
            "Epoch 11/100\n",
            "20000/20000 [==============================] - 3s 162us/step - loss: 0.0339 - accuracy: 0.9902 - val_loss: 0.0856 - val_accuracy: 0.9774\n",
            "Epoch 12/100\n",
            "20000/20000 [==============================] - 3s 161us/step - loss: 0.0362 - accuracy: 0.9887 - val_loss: 0.0507 - val_accuracy: 0.9863\n",
            "Epoch 13/100\n",
            "20000/20000 [==============================] - 3s 161us/step - loss: 0.0239 - accuracy: 0.9929 - val_loss: 0.0512 - val_accuracy: 0.9856\n",
            "Epoch 14/100\n",
            "20000/20000 [==============================] - 3s 161us/step - loss: 0.0228 - accuracy: 0.9925 - val_loss: 0.0425 - val_accuracy: 0.9883\n",
            "Epoch 15/100\n",
            "20000/20000 [==============================] - 3s 161us/step - loss: 0.0219 - accuracy: 0.9934 - val_loss: 0.0465 - val_accuracy: 0.9865\n",
            "Epoch 16/100\n",
            "20000/20000 [==============================] - 3s 161us/step - loss: 0.0168 - accuracy: 0.9948 - val_loss: 0.0744 - val_accuracy: 0.9795\n",
            "Epoch 17/100\n",
            "20000/20000 [==============================] - 3s 161us/step - loss: 0.0178 - accuracy: 0.9944 - val_loss: 0.0516 - val_accuracy: 0.9860\n",
            "Epoch 18/100\n",
            "20000/20000 [==============================] - 3s 162us/step - loss: 0.0149 - accuracy: 0.9952 - val_loss: 0.0608 - val_accuracy: 0.9843\n",
            "Epoch 19/100\n",
            "20000/20000 [==============================] - 3s 161us/step - loss: 0.0123 - accuracy: 0.9960 - val_loss: 0.0644 - val_accuracy: 0.9836\n",
            "Epoch 20/100\n",
            "20000/20000 [==============================] - 3s 161us/step - loss: 0.0073 - accuracy: 0.9977 - val_loss: 0.1209 - val_accuracy: 0.9734\n",
            "Epoch 21/100\n",
            "20000/20000 [==============================] - 3s 163us/step - loss: 0.0236 - accuracy: 0.9920 - val_loss: 0.0468 - val_accuracy: 0.9866\n",
            "Epoch 22/100\n",
            "20000/20000 [==============================] - 3s 162us/step - loss: 0.0055 - accuracy: 0.9981 - val_loss: 0.0519 - val_accuracy: 0.9881\n",
            "Epoch 23/100\n",
            "20000/20000 [==============================] - 3s 163us/step - loss: 0.0105 - accuracy: 0.9968 - val_loss: 0.0696 - val_accuracy: 0.9837\n",
            "Epoch 24/100\n",
            "20000/20000 [==============================] - 3s 162us/step - loss: 0.0074 - accuracy: 0.9973 - val_loss: 0.0661 - val_accuracy: 0.9847\n",
            "Epoch 25/100\n",
            "20000/20000 [==============================] - 3s 163us/step - loss: 0.0074 - accuracy: 0.9973 - val_loss: 0.0648 - val_accuracy: 0.9854\n",
            "Epoch 26/100\n",
            "20000/20000 [==============================] - 3s 162us/step - loss: 0.0046 - accuracy: 0.9988 - val_loss: 0.0597 - val_accuracy: 0.9877\n",
            "Epoch 27/100\n",
            "20000/20000 [==============================] - 3s 162us/step - loss: 0.0062 - accuracy: 0.9982 - val_loss: 0.0737 - val_accuracy: 0.9839\n",
            "Epoch 28/100\n",
            "20000/20000 [==============================] - 3s 163us/step - loss: 0.0028 - accuracy: 0.9991 - val_loss: 0.0723 - val_accuracy: 0.9858\n",
            "Epoch 29/100\n",
            "20000/20000 [==============================] - 3s 162us/step - loss: 0.0081 - accuracy: 0.9972 - val_loss: 0.1171 - val_accuracy: 0.9770\n",
            "Epoch 30/100\n",
            "20000/20000 [==============================] - 3s 162us/step - loss: 0.0088 - accuracy: 0.9973 - val_loss: 0.0592 - val_accuracy: 0.9884\n",
            "Epoch 31/100\n",
            "20000/20000 [==============================] - 3s 163us/step - loss: 0.0013 - accuracy: 0.9997 - val_loss: 0.0652 - val_accuracy: 0.9877\n",
            "Epoch 32/100\n",
            "20000/20000 [==============================] - 3s 162us/step - loss: 0.0118 - accuracy: 0.9962 - val_loss: 0.0559 - val_accuracy: 0.9880\n",
            "Epoch 33/100\n",
            "20000/20000 [==============================] - 3s 161us/step - loss: 0.0016 - accuracy: 0.9996 - val_loss: 0.0583 - val_accuracy: 0.9894\n",
            "Epoch 34/100\n",
            "20000/20000 [==============================] - 3s 161us/step - loss: 2.5122e-04 - accuracy: 0.9999 - val_loss: 0.0612 - val_accuracy: 0.9896\n",
            "Epoch 35/100\n",
            "20000/20000 [==============================] - 3s 162us/step - loss: 4.6190e-05 - accuracy: 1.0000 - val_loss: 0.0643 - val_accuracy: 0.9893\n",
            "Epoch 36/100\n",
            "20000/20000 [==============================] - 3s 162us/step - loss: 2.2673e-05 - accuracy: 1.0000 - val_loss: 0.0659 - val_accuracy: 0.9898\n",
            "Epoch 37/100\n",
            "20000/20000 [==============================] - 3s 163us/step - loss: 1.5141e-05 - accuracy: 1.0000 - val_loss: 0.0674 - val_accuracy: 0.9898\n",
            "Epoch 38/100\n",
            "20000/20000 [==============================] - 3s 162us/step - loss: 1.1874e-05 - accuracy: 1.0000 - val_loss: 0.0686 - val_accuracy: 0.9898\n",
            "Epoch 39/100\n",
            "20000/20000 [==============================] - 3s 162us/step - loss: 9.8595e-06 - accuracy: 1.0000 - val_loss: 0.0696 - val_accuracy: 0.9897\n",
            "Epoch 40/100\n",
            "20000/20000 [==============================] - 3s 163us/step - loss: 8.4007e-06 - accuracy: 1.0000 - val_loss: 0.0705 - val_accuracy: 0.9897\n",
            "Epoch 41/100\n",
            "20000/20000 [==============================] - 3s 162us/step - loss: 7.3120e-06 - accuracy: 1.0000 - val_loss: 0.0712 - val_accuracy: 0.9899\n",
            "Epoch 42/100\n",
            "20000/20000 [==============================] - 3s 160us/step - loss: 6.4594e-06 - accuracy: 1.0000 - val_loss: 0.0720 - val_accuracy: 0.9898\n",
            "Epoch 43/100\n",
            "20000/20000 [==============================] - 3s 161us/step - loss: 5.7827e-06 - accuracy: 1.0000 - val_loss: 0.0726 - val_accuracy: 0.9897\n",
            "Epoch 44/100\n",
            "20000/20000 [==============================] - 3s 161us/step - loss: 5.2515e-06 - accuracy: 1.0000 - val_loss: 0.0732 - val_accuracy: 0.9897\n",
            "Epoch 45/100\n",
            "20000/20000 [==============================] - 3s 162us/step - loss: 4.7680e-06 - accuracy: 1.0000 - val_loss: 0.0737 - val_accuracy: 0.9897\n",
            "Epoch 46/100\n",
            "20000/20000 [==============================] - 3s 163us/step - loss: 4.3822e-06 - accuracy: 1.0000 - val_loss: 0.0742 - val_accuracy: 0.9898\n",
            "Epoch 47/100\n",
            "20000/20000 [==============================] - 3s 163us/step - loss: 4.0795e-06 - accuracy: 1.0000 - val_loss: 0.0747 - val_accuracy: 0.9898\n",
            "Epoch 48/100\n",
            "20000/20000 [==============================] - 3s 163us/step - loss: 3.7724e-06 - accuracy: 1.0000 - val_loss: 0.0752 - val_accuracy: 0.9898\n",
            "Epoch 49/100\n",
            "20000/20000 [==============================] - 3s 162us/step - loss: 3.5478e-06 - accuracy: 1.0000 - val_loss: 0.0756 - val_accuracy: 0.9898\n",
            "Epoch 50/100\n",
            "20000/20000 [==============================] - 3s 162us/step - loss: 3.3244e-06 - accuracy: 1.0000 - val_loss: 0.0760 - val_accuracy: 0.9898\n",
            "Epoch 51/100\n",
            "20000/20000 [==============================] - 3s 162us/step - loss: 3.1343e-06 - accuracy: 1.0000 - val_loss: 0.0764 - val_accuracy: 0.9898\n",
            "Epoch 52/100\n",
            "20000/20000 [==============================] - 3s 162us/step - loss: 2.9613e-06 - accuracy: 1.0000 - val_loss: 0.0767 - val_accuracy: 0.9898\n",
            "Epoch 53/100\n",
            "20000/20000 [==============================] - 3s 163us/step - loss: 2.8110e-06 - accuracy: 1.0000 - val_loss: 0.0771 - val_accuracy: 0.9898\n",
            "Epoch 54/100\n",
            "20000/20000 [==============================] - 3s 162us/step - loss: 2.6643e-06 - accuracy: 1.0000 - val_loss: 0.0774 - val_accuracy: 0.9899\n",
            "Epoch 55/100\n",
            "20000/20000 [==============================] - 3s 162us/step - loss: 2.5354e-06 - accuracy: 1.0000 - val_loss: 0.0777 - val_accuracy: 0.9899\n",
            "Epoch 56/100\n",
            "20000/20000 [==============================] - 3s 161us/step - loss: 2.4199e-06 - accuracy: 1.0000 - val_loss: 0.0780 - val_accuracy: 0.9899\n",
            "Epoch 57/100\n",
            "20000/20000 [==============================] - 3s 161us/step - loss: 2.3144e-06 - accuracy: 1.0000 - val_loss: 0.0783 - val_accuracy: 0.9899\n",
            "Epoch 58/100\n",
            "20000/20000 [==============================] - 3s 162us/step - loss: 2.2178e-06 - accuracy: 1.0000 - val_loss: 0.0786 - val_accuracy: 0.9899\n",
            "Epoch 59/100\n",
            "20000/20000 [==============================] - 3s 162us/step - loss: 2.1252e-06 - accuracy: 1.0000 - val_loss: 0.0788 - val_accuracy: 0.9899\n",
            "Epoch 60/100\n",
            "20000/20000 [==============================] - 3s 162us/step - loss: 2.0455e-06 - accuracy: 1.0000 - val_loss: 0.0791 - val_accuracy: 0.9898\n",
            "Epoch 61/100\n",
            "20000/20000 [==============================] - 3s 162us/step - loss: 1.9634e-06 - accuracy: 1.0000 - val_loss: 0.0793 - val_accuracy: 0.9899\n",
            "Epoch 62/100\n",
            "20000/20000 [==============================] - 3s 162us/step - loss: 1.8923e-06 - accuracy: 1.0000 - val_loss: 0.0796 - val_accuracy: 0.9898\n",
            "Epoch 63/100\n",
            "20000/20000 [==============================] - 3s 162us/step - loss: 1.8260e-06 - accuracy: 1.0000 - val_loss: 0.0798 - val_accuracy: 0.9898\n",
            "Epoch 64/100\n",
            "20000/20000 [==============================] - 3s 162us/step - loss: 1.7639e-06 - accuracy: 1.0000 - val_loss: 0.0800 - val_accuracy: 0.9898\n",
            "Epoch 65/100\n",
            "20000/20000 [==============================] - 3s 162us/step - loss: 1.7061e-06 - accuracy: 1.0000 - val_loss: 0.0802 - val_accuracy: 0.9898\n",
            "Epoch 66/100\n",
            "20000/20000 [==============================] - 3s 162us/step - loss: 1.6514e-06 - accuracy: 1.0000 - val_loss: 0.0804 - val_accuracy: 0.9898\n",
            "Epoch 67/100\n",
            "20000/20000 [==============================] - 3s 162us/step - loss: 1.5986e-06 - accuracy: 1.0000 - val_loss: 0.0806 - val_accuracy: 0.9898\n",
            "Epoch 68/100\n",
            "20000/20000 [==============================] - 3s 162us/step - loss: 1.5506e-06 - accuracy: 1.0000 - val_loss: 0.0808 - val_accuracy: 0.9897\n",
            "Epoch 69/100\n",
            "20000/20000 [==============================] - 3s 161us/step - loss: 1.5052e-06 - accuracy: 1.0000 - val_loss: 0.0810 - val_accuracy: 0.9896\n",
            "Epoch 70/100\n",
            "20000/20000 [==============================] - 3s 162us/step - loss: 1.4617e-06 - accuracy: 1.0000 - val_loss: 0.0812 - val_accuracy: 0.9896\n",
            "Epoch 71/100\n",
            "20000/20000 [==============================] - 3s 163us/step - loss: 1.4221e-06 - accuracy: 1.0000 - val_loss: 0.0814 - val_accuracy: 0.9896\n",
            "Epoch 72/100\n",
            "20000/20000 [==============================] - 3s 163us/step - loss: 1.3827e-06 - accuracy: 1.0000 - val_loss: 0.0816 - val_accuracy: 0.9896\n",
            "Epoch 73/100\n",
            "20000/20000 [==============================] - 3s 163us/step - loss: 1.3463e-06 - accuracy: 1.0000 - val_loss: 0.0817 - val_accuracy: 0.9896\n",
            "Epoch 74/100\n",
            "20000/20000 [==============================] - 3s 163us/step - loss: 1.3127e-06 - accuracy: 1.0000 - val_loss: 0.0819 - val_accuracy: 0.9896\n",
            "Epoch 75/100\n",
            "20000/20000 [==============================] - 3s 162us/step - loss: 1.2787e-06 - accuracy: 1.0000 - val_loss: 0.0821 - val_accuracy: 0.9895\n",
            "Epoch 76/100\n",
            "20000/20000 [==============================] - 3s 162us/step - loss: 1.2456e-06 - accuracy: 1.0000 - val_loss: 0.0823 - val_accuracy: 0.9895\n",
            "Epoch 77/100\n",
            "20000/20000 [==============================] - 3s 163us/step - loss: 1.2174e-06 - accuracy: 1.0000 - val_loss: 0.0824 - val_accuracy: 0.9895\n",
            "Epoch 78/100\n",
            "20000/20000 [==============================] - 3s 164us/step - loss: 1.1888e-06 - accuracy: 1.0000 - val_loss: 0.0826 - val_accuracy: 0.9895\n",
            "Epoch 79/100\n",
            "20000/20000 [==============================] - 3s 163us/step - loss: 1.1602e-06 - accuracy: 1.0000 - val_loss: 0.0827 - val_accuracy: 0.9895\n",
            "Epoch 80/100\n",
            "20000/20000 [==============================] - 3s 163us/step - loss: 1.1348e-06 - accuracy: 1.0000 - val_loss: 0.0829 - val_accuracy: 0.9895\n",
            "Epoch 81/100\n",
            "20000/20000 [==============================] - 3s 163us/step - loss: 1.1097e-06 - accuracy: 1.0000 - val_loss: 0.0830 - val_accuracy: 0.9895\n",
            "Epoch 82/100\n",
            "20000/20000 [==============================] - 3s 161us/step - loss: 1.0852e-06 - accuracy: 1.0000 - val_loss: 0.0832 - val_accuracy: 0.9895\n",
            "Epoch 83/100\n",
            "20000/20000 [==============================] - 3s 162us/step - loss: 1.0627e-06 - accuracy: 1.0000 - val_loss: 0.0833 - val_accuracy: 0.9895\n",
            "Epoch 84/100\n",
            "20000/20000 [==============================] - 3s 162us/step - loss: 1.0398e-06 - accuracy: 1.0000 - val_loss: 0.0835 - val_accuracy: 0.9895\n",
            "Epoch 85/100\n",
            "20000/20000 [==============================] - 3s 163us/step - loss: 1.0186e-06 - accuracy: 1.0000 - val_loss: 0.0836 - val_accuracy: 0.9895\n",
            "Epoch 86/100\n",
            "20000/20000 [==============================] - 3s 162us/step - loss: 9.9784e-07 - accuracy: 1.0000 - val_loss: 0.0838 - val_accuracy: 0.9895\n",
            "Epoch 87/100\n",
            "20000/20000 [==============================] - 3s 163us/step - loss: 9.7753e-07 - accuracy: 1.0000 - val_loss: 0.0839 - val_accuracy: 0.9895\n",
            "Epoch 88/100\n",
            "20000/20000 [==============================] - 3s 162us/step - loss: 9.5898e-07 - accuracy: 1.0000 - val_loss: 0.0840 - val_accuracy: 0.9895\n",
            "Epoch 89/100\n",
            "20000/20000 [==============================] - 3s 164us/step - loss: 9.4074e-07 - accuracy: 1.0000 - val_loss: 0.0842 - val_accuracy: 0.9895\n",
            "Epoch 90/100\n",
            "20000/20000 [==============================] - 3s 164us/step - loss: 9.2291e-07 - accuracy: 1.0000 - val_loss: 0.0843 - val_accuracy: 0.9895\n",
            "Epoch 91/100\n",
            "20000/20000 [==============================] - 3s 163us/step - loss: 9.0582e-07 - accuracy: 1.0000 - val_loss: 0.0844 - val_accuracy: 0.9895\n",
            "Epoch 92/100\n",
            "20000/20000 [==============================] - 3s 163us/step - loss: 8.8963e-07 - accuracy: 1.0000 - val_loss: 0.0845 - val_accuracy: 0.9896\n",
            "Epoch 93/100\n",
            "20000/20000 [==============================] - 3s 161us/step - loss: 8.7403e-07 - accuracy: 1.0000 - val_loss: 0.0847 - val_accuracy: 0.9896\n",
            "Epoch 94/100\n",
            "20000/20000 [==============================] - 3s 161us/step - loss: 8.5832e-07 - accuracy: 1.0000 - val_loss: 0.0848 - val_accuracy: 0.9896\n",
            "Epoch 95/100\n",
            "20000/20000 [==============================] - 3s 161us/step - loss: 8.4258e-07 - accuracy: 1.0000 - val_loss: 0.0849 - val_accuracy: 0.9896\n",
            "Epoch 96/100\n",
            "20000/20000 [==============================] - 3s 162us/step - loss: 8.2924e-07 - accuracy: 1.0000 - val_loss: 0.0850 - val_accuracy: 0.9896\n",
            "Epoch 97/100\n",
            "20000/20000 [==============================] - 3s 163us/step - loss: 8.1509e-07 - accuracy: 1.0000 - val_loss: 0.0851 - val_accuracy: 0.9897\n",
            "Epoch 98/100\n",
            "20000/20000 [==============================] - 3s 164us/step - loss: 8.0142e-07 - accuracy: 1.0000 - val_loss: 0.0853 - val_accuracy: 0.9897\n",
            "Epoch 99/100\n",
            "20000/20000 [==============================] - 3s 162us/step - loss: 7.8824e-07 - accuracy: 1.0000 - val_loss: 0.0854 - val_accuracy: 0.9897\n",
            "Epoch 100/100\n",
            "20000/20000 [==============================] - 3s 162us/step - loss: 7.7558e-07 - accuracy: 1.0000 - val_loss: 0.0855 - val_accuracy: 0.9897\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f292254ccf8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nVfTx67lz1SN",
        "colab_type": "text"
      },
      "source": [
        "4. Imrpimimos el Accuacy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kfj9SX9BzTKC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "97de0b56-cad6-4c5b-9207-050123af9e60"
      },
      "source": [
        "score = modelo.evaluate(X_test, y_test)\n",
        "print(score[0], score[1])"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 1s 126us/step\n",
            "0.08548579572775475 0.9897000193595886\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}