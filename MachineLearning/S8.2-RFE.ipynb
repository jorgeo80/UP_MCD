{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eliminación Recursiva de Atributos\n",
    "Este ejemplo muestra cómo utilizar RFE para reducir el número de atributos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conjunto de datos\n",
    "El conjunto de datos es la caracterización de tumores benignos y malignos asociados al cáncer de mama. Cuenta con 30 atributos obtenidos de imágenes de tumores y dos clases posibles de tumores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   mean fractal dimension  ...  worst radius  worst texture  worst perimeter  \\\n",
       "0                 0.07871  ...         25.38          17.33           184.60   \n",
       "1                 0.05667  ...         24.99          23.41           158.80   \n",
       "2                 0.05999  ...         23.57          25.53           152.50   \n",
       "3                 0.09744  ...         14.91          26.50            98.87   \n",
       "4                 0.05883  ...         22.54          16.67           152.20   \n",
       "\n",
       "   worst area  worst smoothness  worst compactness  worst concavity  \\\n",
       "0      2019.0            0.1622             0.6656           0.7119   \n",
       "1      1956.0            0.1238             0.1866           0.2416   \n",
       "2      1709.0            0.1444             0.4245           0.4504   \n",
       "3       567.7            0.2098             0.8663           0.6869   \n",
       "4      1575.0            0.1374             0.2050           0.4000   \n",
       "\n",
       "   worst concave points  worst symmetry  worst fractal dimension  \n",
       "0                0.2654          0.4601                  0.11890  \n",
       "1                0.1860          0.2750                  0.08902  \n",
       "2                0.2430          0.3613                  0.08758  \n",
       "3                0.2575          0.6638                  0.17300  \n",
       "4                0.1625          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "cancer = load_breast_cancer()\n",
    "\n",
    "atributos = pd.DataFrame(cancer.data)\n",
    "atributos.columns = cancer.feature_names\n",
    "\n",
    "etiquetas = cancer.target\n",
    "\n",
    "atributos.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partición de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_entrenamiento, X_prueba, y_entrenamiento, y_prueba = train_test_split(atributos, etiquetas, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estandarización de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "estandarizacion = StandardScaler()\n",
    "estandarizacion.fit(X_entrenamiento)\n",
    "\n",
    "# RFE - Funciona mejor si se Estandarizan los datos\n",
    "Z_entrenamiento = pd.DataFrame(estandarizacion.transform(X_entrenamiento))\n",
    "Z_prueba = pd.DataFrame(estandarizacion.transform(X_prueba))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento de un modelo de Regresión Logística sin RFE\n",
    "Se utilizan los 4096 atributos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.97        63\n",
      "           1       0.97      0.99      0.98       108\n",
      "\n",
      "    accuracy                           0.98       171\n",
      "   macro avg       0.98      0.97      0.97       171\n",
      "weighted avg       0.98      0.98      0.98       171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "modelo = LogisticRegression()\n",
    "modelo.fit(Z_entrenamiento,y_entrenamiento)\n",
    "\n",
    "y_sin_rfe = modelo.predict(Z_prueba)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_prueba,y_sin_rfe))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento de un modelo de Regresión Logística con RFE\n",
    "Al final, se utilizan 15 atributos para el modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) Obtención del subconjunto de atributos con RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False False False False False False  True  True  True False  True False\n",
      "  True  True False  True False False False  True  True  True  True  True\n",
      " False False  True  True False  True]\n",
      "[10  2  6  3 14  5  1  1  1 16  1 13  1  1  9  1 15  8 12  1  1  1  1  1\n",
      "  4 11  1  1  7  1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "# Estas tecnicas solo sirven para modelos supervisados\n",
    "clasificador = LogisticRegression()\n",
    "seleccionador = RFE(clasificador, step = 1)\n",
    "seleccionador.fit(Z_entrenamiento,y_entrenamiento)\n",
    "\n",
    "print(seleccionador.support_)\n",
    "print(seleccionador.ranking_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) Entrenamiento del modelo de Regresión Logística con el subconjunto de atributos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>10</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>15</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>29</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>-0.457550</td>\n",
       "      <td>-0.760550</td>\n",
       "      <td>-0.099860</td>\n",
       "      <td>-0.700612</td>\n",
       "      <td>-0.616731</td>\n",
       "      <td>-0.543408</td>\n",
       "      <td>-0.235489</td>\n",
       "      <td>-0.045963</td>\n",
       "      <td>-0.798483</td>\n",
       "      <td>-0.591967</td>\n",
       "      <td>-0.746602</td>\n",
       "      <td>-0.714529</td>\n",
       "      <td>-0.046272</td>\n",
       "      <td>-0.623597</td>\n",
       "      <td>0.450628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>-0.843301</td>\n",
       "      <td>-0.808805</td>\n",
       "      <td>-1.159759</td>\n",
       "      <td>-0.887604</td>\n",
       "      <td>-0.869191</td>\n",
       "      <td>-0.629005</td>\n",
       "      <td>-0.936002</td>\n",
       "      <td>-0.158707</td>\n",
       "      <td>-1.068703</td>\n",
       "      <td>-0.161981</td>\n",
       "      <td>-1.074343</td>\n",
       "      <td>-0.868941</td>\n",
       "      <td>-0.954894</td>\n",
       "      <td>-0.761238</td>\n",
       "      <td>-0.295414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>-0.639856</td>\n",
       "      <td>-0.668125</td>\n",
       "      <td>0.581758</td>\n",
       "      <td>-0.644071</td>\n",
       "      <td>-0.656119</td>\n",
       "      <td>-0.499806</td>\n",
       "      <td>-0.563799</td>\n",
       "      <td>-0.474919</td>\n",
       "      <td>-0.558512</td>\n",
       "      <td>-0.051227</td>\n",
       "      <td>-0.614110</td>\n",
       "      <td>-0.552748</td>\n",
       "      <td>-0.384602</td>\n",
       "      <td>-0.504704</td>\n",
       "      <td>-0.133716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>-0.091016</td>\n",
       "      <td>0.221141</td>\n",
       "      <td>-0.663712</td>\n",
       "      <td>-0.515663</td>\n",
       "      <td>-0.498094</td>\n",
       "      <td>-0.250449</td>\n",
       "      <td>-0.946767</td>\n",
       "      <td>-1.005230</td>\n",
       "      <td>0.998276</td>\n",
       "      <td>0.134448</td>\n",
       "      <td>0.914190</td>\n",
       "      <td>0.863760</td>\n",
       "      <td>0.441794</td>\n",
       "      <td>0.638339</td>\n",
       "      <td>-0.799466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>-1.137578</td>\n",
       "      <td>-1.263267</td>\n",
       "      <td>0.439011</td>\n",
       "      <td>-0.630106</td>\n",
       "      <td>-0.623375</td>\n",
       "      <td>-0.633968</td>\n",
       "      <td>-0.848096</td>\n",
       "      <td>0.138526</td>\n",
       "      <td>-1.699888</td>\n",
       "      <td>-0.976348</td>\n",
       "      <td>-1.665615</td>\n",
       "      <td>-1.187480</td>\n",
       "      <td>-1.391304</td>\n",
       "      <td>-1.756275</td>\n",
       "      <td>0.563260</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         6         7         8         10        12        13        15  \\\n",
       "0 -0.457550 -0.760550 -0.099860 -0.700612 -0.616731 -0.543408 -0.235489   \n",
       "1 -0.843301 -0.808805 -1.159759 -0.887604 -0.869191 -0.629005 -0.936002   \n",
       "2 -0.639856 -0.668125  0.581758 -0.644071 -0.656119 -0.499806 -0.563799   \n",
       "3 -0.091016  0.221141 -0.663712 -0.515663 -0.498094 -0.250449 -0.946767   \n",
       "4 -1.137578 -1.263267  0.439011 -0.630106 -0.623375 -0.633968 -0.848096   \n",
       "\n",
       "         19        20        21        22        23        26        27  \\\n",
       "0 -0.045963 -0.798483 -0.591967 -0.746602 -0.714529 -0.046272 -0.623597   \n",
       "1 -0.158707 -1.068703 -0.161981 -1.074343 -0.868941 -0.954894 -0.761238   \n",
       "2 -0.474919 -0.558512 -0.051227 -0.614110 -0.552748 -0.384602 -0.504704   \n",
       "3 -1.005230  0.998276  0.134448  0.914190  0.863760  0.441794  0.638339   \n",
       "4  0.138526 -1.699888 -0.976348 -1.665615 -1.187480 -1.391304 -1.756275   \n",
       "\n",
       "         29  \n",
       "0  0.450628  \n",
       "1 -0.295414  \n",
       "2 -0.133716  \n",
       "3 -0.799466  \n",
       "4  0.563260  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z_rfe = Z_entrenamiento.loc[:,seleccionador.support_]\n",
    "Z_rfe_prueba = Z_prueba.loc[:,seleccionador.support_]\n",
    "\n",
    "# Muestra del subconjunto de atributos seleccionados\n",
    "Z_rfe.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.94      0.95        63\n",
      "           1       0.96      0.98      0.97       108\n",
      "\n",
      "    accuracy                           0.96       171\n",
      "   macro avg       0.97      0.96      0.96       171\n",
      "weighted avg       0.96      0.96      0.96       171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "modelo_rfe = LogisticRegression()\n",
    "modelo_rfe.fit(Z_rfe,y_entrenamiento)\n",
    "\n",
    "y_con_rfe = modelo_rfe.predict(Z_rfe_prueba)\n",
    "\n",
    "print(classification_report(y_prueba,y_con_rfe))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
